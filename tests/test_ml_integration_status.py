#!/usr/bin/env python3
"""
Test especÃ­fico para verificar el estado de la integraciÃ³n ML.
"""

import asyncio
import aiohttp
import json
from datetime import datetime


async def test_ml_integration():
    """Test the ML integration status."""
    
    print("\nğŸ” VERIFICANDO INTEGRACIÃ“N ML - NGX Voice Sales Agent")
    print("=" * 60)
    
    api_url = "http://localhost:8000"
    
    # First check if server is running
    try:
        async with aiohttp.ClientSession() as session:
            async with session.get(f"{api_url}/health") as response:
                if response.status == 200:
                    print("âœ… Servidor estÃ¡ funcionando")
                else:
                    print(f"âŒ Servidor respondiÃ³ con status: {response.status}")
                    return
    except Exception as e:
        print(f"âŒ No se puede conectar al servidor: {e}")
        print("   AsegÃºrate de que el servidor estÃ© corriendo con: python run.py")
        return
    
    # Test conversation with ML features
    try:
        async with aiohttp.ClientSession() as session:
            # Start conversation
            print("\nğŸ“ Iniciando conversaciÃ³n de prueba...")
            
            start_data = {
                "customer_data": {
                    "name": "ML Test User",
                    "email": "mltest@example.com",
                    "age": 35,
                    "occupation": "CEO"
                }
            }
            
            async with session.post(
                f"{api_url}/conversations/start",
                json=start_data
            ) as response:
                if response.status != 200:
                    print(f"âŒ Error al iniciar conversaciÃ³n: {response.status}")
                    return
                    
                data = await response.json()
                conversation_id = data.get("conversation_id")
                print(f"âœ… ConversaciÃ³n iniciada: {conversation_id}")
            
            # Send test messages that should trigger ML
            test_messages = [
                "Hola, soy CEO y busco optimizar mi productividad ejecutiva",
                "Â¿CuÃ¡nto cuesta el programa PRIME?",
                "Me preocupa no tener tiempo para comprometerme",
                "Â¿QuÃ© ROI puedo esperar de su programa?"
            ]
            
            ml_features_detected = {
                "predictive_insights": False,
                "objection_prediction": False,
                "needs_detection": False,
                "conversion_probability": False,
                "roi_calculation": False
            }
            
            for i, message in enumerate(test_messages):
                print(f"\nğŸ“¤ Mensaje {i+1}: {message}")
                
                async with session.post(
                    f"{api_url}/conversations/{conversation_id}/message",
                    json={"message": message}
                ) as response:
                    if response.status == 200:
                        data = await response.json()
                        response_text = data.get("message", "")
                        
                        # Check for ML features in response
                        if "ml_insights" in data and data["ml_insights"]:
                            ml_features_detected["predictive_insights"] = True
                            print("   âœ… ML insights detectados")
                            
                            insights = data["ml_insights"]
                            if insights.get("objections_predicted"):
                                ml_features_detected["objection_prediction"] = True
                                objs = insights['objections_predicted'].get('objections', [])
                                if objs:
                                    print(f"   âœ… Objeciones predichas: {objs[0].get('type', 'unknown')}")
                            
                            if insights.get("needs_detected"):
                                ml_features_detected["needs_detection"] = True
                                needs = insights['needs_detected'].get('needs', [])
                                if needs:
                                    print(f"   âœ… Necesidades detectadas: {needs[0].get('type', 'unknown')}")
                                elif insights['needs_detected'].get('primary_need'):
                                    ml_features_detected["needs_detection"] = True
                                    print(f"   âœ… Necesidad primaria: {insights['needs_detected']['primary_need']}")
                            
                            if insights.get("conversion_probability", 0) > 0:
                                ml_features_detected["conversion_probability"] = True
                                print(f"   âœ… Probabilidad de conversiÃ³n: {insights['conversion_probability']:.2%}")
                        
                        # Check response quality indicators
                        if any(word in response_text.lower() for word in ["roi", "retorno", "inversiÃ³n"]):
                            ml_features_detected["roi_calculation"] = True
                            print("   âœ… ROI mencionado en respuesta")
                        
                        # Print part of response
                        print(f"   ğŸ“¥ Respuesta: {response_text[:100]}...")
                    else:
                        print(f"   âŒ Error en mensaje: {response.status}")
            
            # Get conversation details to check ML tracking
            async with session.get(
                f"{api_url}/conversations/{conversation_id}"
            ) as response:
                if response.status == 200:
                    conv_data = await response.json()
                    
                    # Check for ML metadata
                    if "ml_metadata" in conv_data:
                        print("\nâœ… Metadata ML encontrada en conversaciÃ³n")
                        ml_features_detected["conversion_probability"] = True
    
    except Exception as e:
        print(f"\nâŒ Error durante la prueba: {e}")
        import traceback
        traceback.print_exc()
    
    # Summary
    print("\n" + "=" * 60)
    print("ğŸ“Š RESUMEN DE INTEGRACIÃ“N ML")
    print("=" * 60)
    
    working_features = sum(1 for v in ml_features_detected.values() if v)
    total_features = len(ml_features_detected)
    
    for feature, status in ml_features_detected.items():
        icon = "âœ…" if status else "âŒ"
        print(f"{icon} {feature.replace('_', ' ').title()}")
    
    success_rate = (working_features / total_features) * 100
    print(f"\nCaracterÃ­sticas ML funcionando: {working_features}/{total_features}")
    print(f"Tasa de Ã©xito: {success_rate:.1f}%")
    
    if success_rate > 80:
        print("\nğŸ‰ INTEGRACIÃ“N ML FUNCIONANDO CORRECTAMENTE")
    elif success_rate > 50:
        print("\nâš ï¸  INTEGRACIÃ“N ML PARCIALMENTE FUNCIONAL")
    else:
        print("\nâŒ INTEGRACIÃ“N ML REQUIERE ATENCIÃ“N")
    
    # Save results
    results = {
        "timestamp": datetime.now().isoformat(),
        "ml_features_detected": ml_features_detected,
        "success_rate": success_rate,
        "working_features": working_features,
        "total_features": total_features
    }
    
    with open("ml_integration_test_results.json", "w") as f:
        json.dump(results, f, indent=2)
    
    print(f"\nğŸ’¾ Resultados guardados en: ml_integration_test_results.json")


if __name__ == "__main__":
    asyncio.run(test_ml_integration())